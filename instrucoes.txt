PASSO A PASSO GERAL DE COMO BAIXAR, ANALISAR E PREPARAR O DATASET PARA
TREINAMENTO DA REDE NEURAL.

Muito importante: executar os arquivos pela numeração para obter o melhor resultado.

===========================================================================

1. CONFIGURAÇÕES DO AMBIENTE E DOWNLOAD DO DATASET
--------------------------------------------------

1.1. Instalar a API do Kaggle:
     pip install kaggle

1.2. Criar o token de acesso no Kaggle:
     - Acessar kaggle.com → Perfil → Settings → Create New Token
     - Isso gera o arquivo "kaggle.json"
     - Salvar o arquivo em:
           C:\Users\<SEU-USUARIO>\.kaggle\kaggle.json
       (Se a pasta .kaggle não existir, criar manualmente)

1.3. Importar a API no código Python:
     from kaggle import api

1.4. Escolher o dataset:
     O link deve ser no formato:
     kaggle.com/datasets/<CRIADOR>/<NOME-DO-DATASET>

1.5. Definir constantes para download:
     - DATASET_REF = "<CRIADOR>/<NOME-DO-DATASET>"
     - DESTINO = "./dados_jogadores"

1.6. Rodar o arquivo de download (01_baixar_dataset.py)
     Isso criará a pasta de dados e salvará o CSV do Kaggle.

===========================================================================

2. ANÁLISE INICIAL DO DATASET (02_analise_inicial.py)
-----------------------------------------------------

2.1. Importar o pandas:
     import pandas as pd

2.2. Carregar o CSV original e visualizar informações:
     - df.head(): primeiros registros do dataset
     - df.columns: nome de todas as colunas
     - df.info(): tipos de dados, quantidades e uso de memória
     - df["League"].unique(): valores únicos da coluna "League"
     - df["Season"].unique(): valores únicos da coluna "Season"
     - df["Stage"].unique(): valores únicos da coluna "Stage"

2.3. O objetivo é compreender a estrutura do dataset original e
     identificar os valores corretos antes de realizar filtragens.

===========================================================================

3. FILTRAGEM DO DATASET (03_filtrar_dataset.py)
------------------------------------------------

Selecionamos apenas dados relevantes para o objetivo do projeto:

- League = NBA  
- Season = 2016 - 2017  
- Stage = Playoffs  

Após a filtragem, o dataset resultante contém apenas
jogadores que atuaram nos Playoffs da NBA 2016–2017.

A saída desse processo gerou o arquivo:
    ./dados_jogadores/nba_playoffs_2016_2017.csv

===========================================================================

4. SELEÇÃO DE CAMPOS (LIMPEZA DO DATASET)
-----------------------------------------

Algumas colunas foram removidas por não influenciar o desempenho real em quadra.
Outras foram mantidas por capturarem impacto estatístico do jogador.

-----------------------------------------------------------
CAMPOS REMOVIDOS (não úteis para análise)
-----------------------------------------------------------

- altura e peso (height, weight)
- birth_year, birth_month, birth_date
- nationality, high_school
- draft_round, draft_pick, draft_team

-----------------------------------------------------------
CAMPOS MANTIDOS (essenciais)
-----------------------------------------------------------

- Identificação: League, Season, Stage, Player, Team
- Volume: GP, MIN
- Arremessos: FGM, FGA, 3PM, 3PA, FTM, FTA
- Rebotes: ORB, DRB, REB
- Criação: AST
- Defesa: STL, BLK
- Pontuação: PTS
- Penalidades: TOV, PF

===========================================================================

5. FEATURE ENGINEERING (05_features_iniciais.py)
-------------------------------------------------

Criamos novas features mais informativas para treinar a rede neural.

-----------------------------------------------------------
A) MÉTRICAS PROPORCIONAIS (por minuto)
-----------------------------------------------------------

- PTS_per_min = PTS / MIN
- REB_per_min = REB / MIN
- AST_per_min = AST / MIN
- STL_per_min = STL / MIN
- BLK_per_min = BLK / MIN
- TOV_per_min = TOV / MIN

-----------------------------------------------------------
B) APROVEITAMENTOS PERCENTUAIS
-----------------------------------------------------------

- FG_pct = FGM / FGA
- 3P_pct = 3PM / 3PA
- FT_pct = FTM / FTA

Divisões impossíveis são tratadas com fillna(0).

-----------------------------------------------------------
C) OBJETIVO
-----------------------------------------------------------

Criar features comparáveis entre jogadores para capturar:
- eficiência ofensiva
- impacto defensivo
- produção por minuto
- risco (turnovers)

-----------------------------------------------------------
D) SALVAMENTO
-----------------------------------------------------------

Arquivo gerado:
    ./dados_jogadores/nba_playoffs_2017_2017_features.csv

===========================================================================

6. NORMALIZAÇÃO + CRIAÇÃO DA EFICIÊNCIA (06_normalizacao_dados.py)
-------------------------------------------------------------------

Após criar as features, é necessário normalizar os dados e criar a métrica
de impacto total (EFF), que será a variável alvo da rede neural.

-----------------------------------------------------------
A) SELEÇÃO DE COLUNAS NUMÉRICAS
-----------------------------------------------------------

    df_numerico = df.select_dtypes(include=['float64', 'int64'])

-----------------------------------------------------------
B) APLICAÇÃO DO MINMAXSCALER
-----------------------------------------------------------

Escala os dados para o intervalo [0, 1]:

    scaler = MinMaxScaler()
    dados_normalizados = scaler.fit_transform(df_numerico)

-----------------------------------------------------------
C) RECONSTRUÇÃO DO DATAFRAME NORMALIZADO
-----------------------------------------------------------

Preserva os nomes das features:

    df_normalizado = pd.DataFrame(
        dados_normalizados,
        columns=df_numerico.columns
    )

-----------------------------------------------------------
D) CRIAÇÃO DA MÉTRICA DE EFICIÊNCIA (EFF)
-----------------------------------------------------------

Fórmula adaptada da NBA:

    EFF = (PTS + REB + AST + STL + BLK)
          - ((FGA - FGM) + (FTA - FTM) + TOV_per_min)

-----------------------------------------------------------
E) SALVAMENTO DOS RESULTADOS
-----------------------------------------------------------

- Dataset final:
      ./dados_jogadores/nba_playoffs_2016_2017_normalizado.csv

- Scaler salvo:
      ./dados_jogadores/scaler_normalizacao.pkl

-----------------------------------------------------------
F) OBJETIVO
-----------------------------------------------------------

A normalização:
- evita dominância de valores grandes
- estabiliza o treinamento
- coloca todas as features em mesma escala
- prepara os dados para uso direto no PyTorch

===========================================================================

7. TREINAMENTO DA REDE NEURAL (07_treinamento_rede.py)
------------------------------------------------------

Utilizando PyTorch, foi treinada uma MLP para prever a eficiência (EFF).

-----------------------------------------------------------
A) PREPARAÇÃO DOS DADOS
-----------------------------------------------------------

- X = features normalizadas
- y = coluna EFF
- divisão treino/teste → 80%/20%
- conversão para tensores PyTorch

-----------------------------------------------------------
B) ARQUITETURA DA REDE
-----------------------------------------------------------

Entrada: 26 features  
Camadas:
- Linear(26 → 64) + função de ativação
- Linear(64 → 32) + função de ativação
- Linear(32 → 1)  (saída)

Funções testadas:
- ReLU
- Tanh

Saída sem ativação → problema de regressão.

-----------------------------------------------------------
C) LOOP DE TREINAMENTO
-----------------------------------------------------------

- Loss: MSELoss  
- Otimizador: Adam (η = 0.001)  
- Épocas: 200  
- Tamanho do lote: 16  

A cada 20 épocas, exibe a perda média.

-----------------------------------------------------------
D) RESULTADOS
-----------------------------------------------------------

Curvas de perda geradas com Matplotlib.

Desempenho final:

    ReLU → MSE = 0.001007 | R² = 0.9971  
    Tanh → MSE = 0.001708 | R² = 0.9951  

ReLU escolhido como modelo final.

===========================================================================

8. PREVISÕES, SIMULAÇÃO DE JOGO E ESCOLHA DO MELHOR JOGADOR
   (08_previsoes.py)
------------------------------------------------------------------

Esta etapa utiliza o modelo treinado (arquitetura MLP + ReLU) para realizar
previsões reais de eficiência (EFF) e simular um cenário de jogo — requisito
fundamental para transformar o modelo em uma ferramenta aplicada ao basquete.

O arquivo 08_previsoes.py é responsável por:

    ✓ carregar o modelo treinado (ReLU)  
    ✓ carregar o scaler usado na normalização    
    ✓ carregar o dataset real dos jogadores dos Playoffs 2016–2017  
    ✓ prever EFF para jogadores individuais ou para um time inteiro  
    ✓ simular um cenário de jogo (tempo, placar, jogadores em quadra)  
    ✓ recomendar o melhor jogador do banco segundo o modelo  
    ✓ gerar um gráfico destacando o jogador recomendado  

Esta etapa converte o modelo em uma ferramenta prática capaz de responder:
"Quem deve entrar em quadra agora para tentar virar o jogo?"

---------------------------------------------------------------------------
A) CARREGAMENTO DO MODELO E DO SCALER
---------------------------------------------------------------------------

O arquivo carrega:

- modelo_eff_relu.pth: pesos do modelo treinado
- scaler_normalizacao.pkl: scaler usado no arquivo 06

Isso garante que **novos dados** passem pela **mesma normalização** usada no treino,
evitando previsões incorretas.

---------------------------------------------------------------------------
B) FUNÇÃO DE PREVISÃO PARA VÁRIOS JOGADORES
---------------------------------------------------------------------------

A função:

    prever_jogadores(df)

Recebe um DataFrame contendo as features numéricas (GP, MIN, FGM, 3PA, etc.),
aplica o scaler, passa no modelo e retorna a coluna:

    EFF_prevista

Ela funciona para:

    - 1 jogador
    - vários jogadores
    - um time inteiro

---------------------------------------------------------------------------
C) FUNÇÃO DE ESCOLHA DO MELHOR JOGADOR
---------------------------------------------------------------------------

A função:

    escolher_melhor_jogador(df)

Ordena os jogadores pelas suas EFF_prevista e retorna:

    - nome do melhor jogador
    - seu valor de EFF prevista
    - explicação em forma de texto para o relatório

Exemplo de saída:

“Stephen Curry (GSW) é o melhor candidato para entrar, com EFF prevista de 2.750,
indicando maior impacto ofensivo e defensivo segundo o modelo treinado.”

---------------------------------------------------------------------------
D) SIMULAÇÃO DE CENÁRIO DE JOGO
---------------------------------------------------------------------------

A função:

    simular_cenario_jogo(time, minutos_restantes, diferenca_pontos)

simula uma situação realista:

1. Seleciona todos os jogadores do time no dataset real  
2. Sorteia 5 jogadores que estão em quadra  
3. Define o banco como os demais jogadores  
4. Usa o modelo para prever a EFF de cada jogador do banco  
5. Recomenda o jogador ideal para entrar em quadra  
6. Exibe um gráfico comparando EFF de todo o time

Os argumentos controlam o contexto:

- `minutos_restantes` → ex.: faltando 4 minutos  
- `diferenca_pontos` → ex.: time está perdendo por −11  

Isso permite simular situações como:

    “Golden State Warriors está perdendo por 11 pontos faltando 4 minutos.
     Quem deve entrar para tentar virar o jogo?”

---------------------------------------------------------------------------
E) GRÁFICO DE EFF COM O JOGADOR RECOMENDADO
---------------------------------------------------------------------------

Após a simulação, é gerado automaticamente um gráfico de barras contendo:

- EFF prevista de cada jogador do time
- barras azuis para todos os jogadores
- barra vermelha destacando o recomendado
- linha tracejada representando o valor recomendado

Exemplo de leitura:

“Draymond Green aparece como a barra vermelha com maior EFF prevista, logo ele é o jogador ideal para entrar.”

---------------------------------------------------------------------------
F) EXECUÇÃO EXEMPLO
---------------------------------------------------------------------------

    simular_cenario_jogo("GSW", minutos_restantes=4, diferenca_pontos=-11)

Saída típica:

- lista dos jogadores disponíveis
- lista dos 5 jogadores em quadra (sorteados dinamicamente)
- situação do jogo
- recomendação do melhor jogador
- gráfico de impacto de todo o time

---------------------------------------------------------------------------

OBJETIVO FINAL DA ETAPA
---------------------------------------------------------------------------

Esta etapa conecta **todos os blocos do projeto**, permitindo:

- utilizar o modelo e as features criadas  
- realizar previsões reais de desempenho  
- aplicar o modelo para tomada de decisão em jogo  
- analisar “quem entra para tentar virar o placar”  
- visualizar graficamente o impacto de cada jogador  

Com isso, o projeto deixa de ser apenas estatístico e se torna uma ferramenta
**inteligente, aplicada e interpretável**, cumprindo todos os requisitos de
Sistemas Inteligentes.

===========================================================================